{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkxgAuMNbRWr"
      },
      "source": [
        "# Tutorial 8: Exploratory Data Analysis\n",
        "\n",
        "## Background\n",
        "\n",
        "As a data scientist at Heilbronn Hospital, you've been tasked with conducting a thorough exploratory data analysis (EDA) of patient records. The medical team needs to understand patterns in patient care, identify data quality issues, and gain insights that could lead to improved treatment protocols. Your analysis will help the hospital make data-driven decisions about resource allocation and patient care strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBADXmdpbVdv"
      },
      "source": [
        "1. Data Quality Assessment: The ICU's electronic health records system occasionally has gaps in data collection due to emergency situations or equipment issues. Import the dataset 'icu_data_example.csv' into a DataFrame, then identify which vital signs and patient information are most frequently missing by calculating the percentage of missing values in each column. This analysis will help the hospital improve their data collection protocols."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "missing_percentages = df.isnull().mean() * 100\n",
        "\n",
        "missing_percentages_sorted = missing_percentages.sort_values(ascending=False)\n",
        "\n",
        "print(missing_percentages_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9HOFb9SbW6R"
      },
      "source": [
        "2. Data Imputation Strategy: For accurate patient assessment, we need to handle missing data carefully. Implement a for-loop to iterate over all vital sign measurements and replace missing values with the median of the respective column, but only where the missing data is below 20%. This conservative approach ensures we only fill in gaps where we have sufficient reliable data to make educated estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIkTqrhqbXN7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "vital_sign_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "#prettifying the output\n",
        "GREEN = \"\\033[92m\"\n",
        "RED = \"\\033[91m\"\n",
        "RESET = \"\\033[0m\"\n",
        "\n",
        "for col in vital_sign_cols:\n",
        "    missing_pct = df[col].isnull().mean() * 100\n",
        "    if missing_pct < 20:\n",
        "        median_value = df[col].median()\n",
        "        df.fillna({col: median_value}, inplace=True)\n",
        "        print(f\"{GREEN}Filled missing values in '{col}' with median ({median_value}) - missing percentage {missing_pct:.2f}%{RESET}\")\n",
        "    else:\n",
        "        print(f\"{RED}Skipped '{col}' - too much missing data - missing percentage {missing_pct:.2f}%{RESET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsmhLx5JbYRt"
      },
      "source": [
        "3. Outlier Detection: Medical equipment sometimes produces erroneous readings, and transcription errors can occur. Use the Interquartile Range (IQR) method to identify potentially abnormal values in patients' 'weight' and 'Heart Rate' measurements. This will help the medical team verify these readings and ensure accurate patient monitoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-UWbuafbYkA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "def detect_outliers_iqr(series):\n",
        "\tQ1 = series.quantile(0.25)\n",
        "\tQ3 = series.quantile(0.75)\n",
        "\tIQR = Q3 - Q1\n",
        "\tlower_bound = Q1 - 1.5 * IQR\n",
        "\tupper_bound = Q3 + 1.5 * IQR\n",
        "\toutliers = series[(series < lower_bound) | (series > upper_bound)]\n",
        "\treturn outliers, lower_bound, upper_bound\n",
        "\n",
        "weight_outliers, weight_lb, weight_ub = detect_outliers_iqr(df['weight'])\n",
        "print(f\"Weight outliers: {len(weight_outliers)}\")\n",
        "print(f\"Weight range: {weight_lb:.2f} kg – {weight_ub:.2f} kg\")\n",
        "print(\"Weight outlier values:\\n\", weight_outliers)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "hr_outliers, hr_lb, hr_ub = detect_outliers_iqr(df['Heart Rate'])\n",
        "print(f\"Heart rate outliers: {len(hr_outliers)}\")\n",
        "print(f\"Heart rate range: {hr_lb:.2f} bpm – {hr_ub:.2f} bpm\")\n",
        "print(\"Heart rate outlier values:\\n\", hr_outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpApna5fbZn8"
      },
      "source": [
        "4. Age Group Analysis: To better understand the demographics of ICU admissions, create a new column that categorizes patients into clinically relevant age groups (0-20, 21-40, 41-60, etc.). This categorization will help the hospital plan age-specific care protocols and resource allocation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuOCop0obZ3y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "age_bins = [0, 20, 40, 60, 80, 100, float('inf')]\n",
        "age_labels = ['0-20', '21-40', '41-60', '61-80', '81-100', '100+']\n",
        "\n",
        "df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=True)\n",
        "\n",
        "print(df['age_group'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpp-2BbSbau8"
      },
      "source": [
        "5. Gender-based Analysis: The medical team wants to investigate if there are gender-specific patterns in ICU care. Group the data by gender and calculate the median length of ICU stay for each group. This analysis could reveal if certain gender-specific health factors influence recovery time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuYwP875ba7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "st_by_gender = df.groupby('gender')['los'].median()\n",
        "print(\"Median ICU Stay by Gender:\")\n",
        "print(st_by_gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46GGPpzsbcZX"
      },
      "source": [
        "6. Length of Stay Classification: For better resource planning, create a new column that categorizes ICU stays into three groups: Short (<5 days), Medium (5-10 days), and Long (>10 days). Count the number of patients in each category. This information will help the hospital optimize bed allocation and staffing levels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep3rjAf0bcpi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "def classify_stay(days):\n",
        "    if pd.isnull(days):\n",
        "        return 'Unknown'\n",
        "    elif days < 5:\n",
        "        return 'Short'\n",
        "    elif 5 <= days <= 10:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Long'\n",
        "\n",
        "df['StayLengthCategory'] = df['los'].apply(classify_stay)\n",
        "stay_counts = df['StayLengthCategory'].value_counts()\n",
        "print(\"Patients per stay length category:\")\n",
        "print(stay_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI2MvviNbdjr"
      },
      "source": [
        "7. Data Integration: The hospital maintains additional patient information in a separate file 'icu_data_additional.csv'. Merge this dataset with our main ICU data using a common patient identifier. This will provide a more comprehensive view of each patient's medical history and current condition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKtZMfA3bdya"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "additional_df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "merged_df = pd.merge(df, additional_df, how='left', on='stay_id')\n",
        "\n",
        "print(\"merged df shape:\", merged_df.shape)\n",
        "print(\"columns in merged df:\")\n",
        "print(merged_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DUFoTfGbe0_"
      },
      "source": [
        "8. Distribution Analysis: Create histograms of patient ages and heart rates using pandas or matplotlib. Understanding the distribution of these vital statistics will help medical staff better prepare for the typical patient profile and identify unusual cases that might need special attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ0FKhJobfHp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['age'].dropna(), bins=20, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('Patients number')\n",
        "plt.title('Distribution of patient ages')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['Heart Rate'].dropna(), bins=20, color='salmon', edgecolor='black')\n",
        "plt.xlabel('Heart Rate')\n",
        "plt.ylabel('Number of patients')\n",
        "plt.title('Heart rates distribution')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Homework\n",
        "### Homework Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keiQ8rafdM4a"
      },
      "source": [
        "As a member of the data science team at Heilbronn Hospital, you need to develop a universal data cleaning tool to help different departments handle various types of medical data. Different medical indicators may have different missing data tolerance levels, and some indicators are suitable for mean imputation while others are better suited for median imputation. Your task is to design a flexible function to handle these different requirements. **Design a function called `smart_imputation` with the following capabilities**:\n",
        "\n",
        "**Function Parameters**:\n",
        "- `df`: Input DataFrame\n",
        "- `column_name`: Name of the column to process (string)\n",
        "- `threshold`: Missing data threshold percentage (float, e.g., 0.2 for 20%)\n",
        "- `method`: Imputation method (string, 'mean' or 'median')\n",
        "\n",
        "**Function Features**:\n",
        "1. Check the missing data percentage of the specified column\n",
        "2. If missing data percentage is below the given threshold, perform imputation using the specified method\n",
        "3. If missing data percentage is above or equal to the threshold, do not perform imputation and print a warning message\n",
        "4. Return the processed DataFrame and a dictionary containing processing information\n",
        "\n",
        "**Return Values**:\n",
        "- Processed DataFrame\n",
        "- Information dictionary containing:\n",
        "    - `column`: Name of the processed column\n",
        "    - `missing_percentage`: Missing data percentage\n",
        "    - `action_taken`: Action taken ('imputed' or 'no_action')\n",
        "    - `method_used`: Method used (if imputation was performed)\n",
        "\n",
        "**Example**\n",
        "```python\n",
        "result_df, info = smart_imputation(df, 'Heart_Rate', 0.15, 'median')\n",
        "result_df, info = smart_imputation(df, 'Blood_Pressure', 0.25, 'mean')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smart_imputation(df, column_name, threshold, method):\n",
        "\tinfo = {\n",
        "\t\t'column': column_name,\n",
        "\t\t'missing_percentage': None,\n",
        "\t\t'action_taken': 'no_action',\n",
        "\t\t'method_used': None\n",
        "\t}\n",
        "\n",
        "\tif column_name not in df.columns:\n",
        "\t\traise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n",
        "\n",
        "\tmissing_ratio = df[column_name].isnull().mean()\n",
        "\tinfo['missing_percentage'] = missing_ratio\n",
        "\n",
        "\tif missing_ratio < threshold:\n",
        "\t\tif method == 'mean':\n",
        "\t\t\tvalue = df[column_name].mean()\n",
        "\t\telif method == 'median':\n",
        "\t\t\tvalue = df[column_name].median()\n",
        "\t\telse:\n",
        "\t\t\traise ValueError(\"Method must be 'mean' or 'median'.\")\n",
        "\n",
        "\t\tdf.fillna(value, inplace=True)\n",
        "\t\tinfo['action_taken'] = 'imputed'\n",
        "\t\tinfo['method_used'] = method\n",
        "\telse:\n",
        "\t\tprint(f\"Skipped '{column_name}': Missing data {missing_ratio:.2%} exceeds threshold {threshold:.2%}\")\n",
        "\n",
        "\treturn df, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Homework Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcDqRmEFdNMB"
      },
      "source": [
        "As a data analyst at Heilbronn Hospital's Quality Assurance Department, you've discovered that medical equipment occasionally produces anomalous measurements due to sensor malfunctions, patient movement during measurements, or data entry errors. The medical team needs a robust tool to automatically detect and handle these outliers in vital sign measurements. Different medical scenarios may require different outlier detection methods - some prefer the IQR method for its robustness, while others need the z-score method for normally distributed data. Your task is to create a flexible outlier detection and removal system. **Design a function called `outlier_detector` with the following capabilities**:\n",
        "\n",
        "**Function Parameters**:\n",
        "- `df`: Input DataFrame\n",
        "- `column_name`: Name of the column to process (string)\n",
        "- `method`: Outlier detection method (string, 'iqr' or 'zscore')\n",
        "- `action`: What to do with outliers (string, 'remove', 'flag', or 'cap')\n",
        "- `threshold`: Threshold parameter (float, default=1.5 for IQR, default=3.0 for z-score)\n",
        "\n",
        "**Function Features**:\n",
        "1. Detect outliers using the specified method (IQR or z-score)\n",
        "2. Handle outliers based on the specified action:\n",
        "    - 'remove': Remove outlier rows from DataFrame\n",
        "    - 'flag': Add a boolean column indicating outliers\n",
        "    - 'cap': Cap outliers to threshold boundaries\n",
        "3. Provide detailed statistics about outliers detected\n",
        "4. Return the processed DataFrame and comprehensive outlier information\n",
        "\n",
        "**Return Values**:\n",
        "- Processed DataFrame\n",
        "- Information dictionary containing:\n",
        "    - `column`: Name of the processed column\n",
        "    - `method_used`: Detection method used\n",
        "    - `action_taken`: Action performed on outliers\n",
        "    - `outliers_detected`: Number of outliers found\n",
        "    - `outliers_percentage`: Percentage of outliers\n",
        "    - `outlier_indices`: List of outlier indices (if action != 'remove')\n",
        "    - `bounds`: Upper and lower bounds used for detection\n",
        "    - `original_shape`: Original DataFrame shape\n",
        "    - `final_shape`: Final DataFrame shape\n",
        "\n",
        "**Example**\n",
        "```python\n",
        "result_df, info = outlier_detector(df, 'Heart_Rate', 'iqr', 'remove', 1.5)\n",
        "result_df, info = outlier_detector(df, 'Weight', 'zscore', 'flag', 3.0)\n",
        "result_df, info = outlier_detector(df, 'Blood_Pressure', 'iqr', 'cap', 2.0)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def outlier_detector(df, column_name, method='iqr', action='remove', threshold=None):\n",
        "\tif column_name not in df.columns:\n",
        "\t\traise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n",
        "\n",
        "\tif method == 'iqr' and threshold is None:\n",
        "\t\tthreshold = 1.5\n",
        "\telif method == 'zscore' and threshold is None:\n",
        "\t\tthreshold = 3.0    \n",
        "\tseries = df[column_name]\n",
        "\toriginal_shape = df.shape\n",
        "\n",
        "\tif method == 'iqr':\n",
        "\t\tQ1 = series.quantile(0.25)\n",
        "\t\tQ3 = series.quantile(0.75)\n",
        "\t\tIQR = Q3 - Q1\n",
        "\t\tlower_bound = Q1 - threshold * IQR\n",
        "\t\tupper_bound = Q3 + threshold * IQR\n",
        "\t\toutlier_condition = (series < lower_bound) | (series > upper_bound)\n",
        "\telif method == 'zscore':\n",
        "\t\tz_scores = zscore(series.dropna())\n",
        "\t\toutlier_indices_raw = np.abs(z_scores) > threshold\n",
        "\t\toutlier_condition = pd.Series(False, index=series.index)\n",
        "\t\toutlier_condition[series.dropna().index[outlier_indices_raw]] = True\n",
        "\t\tlower_bound = None\n",
        "\t\tupper_bound = None\n",
        "\telse:\n",
        "\t\traise ValueError(\"Method must be 'iqr' or 'zscore'.\")\n",
        "\n",
        "\toutlier_indices = df[outlier_condition].index.tolist()\n",
        "\toutliers_detected = len(outlier_indices)\n",
        "\toutliers_percentage = (outliers_detected / len(df)) * 100\n",
        "\n",
        "\tif action == 'remove':\n",
        "\t\tdf = df[~outlier_condition].copy()\n",
        "\telif action == 'flag':\n",
        "\t\tflag_col = f\"{column_name}_outlier\"\n",
        "\t\tdf[flag_col] = outlier_condition\n",
        "\telif action == 'cap':\n",
        "\t\tif method != 'iqr':\n",
        "\t\t\traise ValueError(\"Capping is only supported with 'iqr' method.\")\n",
        "\t\tdf[column_name] = np.where(series > upper_bound, upper_bound,\n",
        "\t\tnp.where(series < lower_bound, lower_bound, series))\n",
        "\telse:\n",
        "\t\traise ValueError(\"Action must be 'remove', 'flag', or 'cap'.\")\n",
        "\n",
        "\tinfo = {\n",
        "\t\t'column': column_name,\n",
        "\t\t'method_used': method,\n",
        "\t\t'action_taken': action,\n",
        "\t\t'outliers_detected': outliers_detected,\n",
        "\t\t'outliers_percentage': round(outliers_percentage, 2),\n",
        "\t\t'outlier_indices': outlier_indices if action != 'remove' else None,\n",
        "\t\t'bounds': (lower_bound, upper_bound),\n",
        "\t\t'original_shape': original_shape,\n",
        "\t\t'final_shape': df.shape\n",
        "\t}\n",
        "\n",
        "\treturn df, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Homework Question 3\n",
        "Advanced Visualization: Using Seaborn, create a box plot to visualize how patient age varies across different ICU stay duration categories. This visualization will help identify if certain age groups tend to require longer ICU stays, allowing for better prediction of resource needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('icu_data_example.csv')\n",
        "\n",
        "df['los'] = pd.to_numeric(df['los'], errors='coerce')\n",
        "df = df.dropna(subset=['los', 'age'])\n",
        "\n",
        "stay_bins = [0, 1, 3, 7, 14, float('inf')]\n",
        "stay_labels = ['<1 day', '1-3 days', '4-7 days', '8-14 days', '>14 days']\n",
        "df['stay_category'] = pd.cut(df['los'], bins=stay_bins, labels=stay_labels)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='stay_category', y='age', hue='stay_category', data=df, palette=\"coolwarm\", legend=False)\n",
        "\n",
        "plt.title('Patient age distribution across ICU stay duration categories')\n",
        "plt.xlabel('ICU stay duration')\n",
        "plt.ylabel('Age (years)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
